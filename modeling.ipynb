{
<<<<<<< HEAD
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modeling.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_UgGN9bslkhK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "3a478a5a-23c5-49d4-f628-f98753b491ba",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525141757650,
          "user_tz": 240,
          "elapsed": 102730,
          "user": {
            "displayName": "Peter Shen",
            "photoUrl": "//lh3.googleusercontent.com/-4U4XtPOliU0/AAAAAAAAAAI/AAAAAAAAAYc/8wgnQdDGnvA/s50-c-k-no/photo.jpg",
            "userId": "101608421039751327941"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-01 02:27:35--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2018-05-01 02:27:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1       29%[====>               ] 240.82M  6.94MB/s    eta 71s    "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "glove.6B.zip.1      100%[===================>] 822.24M  10.5MB/s    in 1m 41s  \n",
            "\n",
            "2018-05-01 02:29:17 (8.12 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5r8uO2vDloCb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ded22cb8-c6e9-445e-ffbe-e2654423f22d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525141921807,
          "user_tz": 240,
          "elapsed": 139245,
          "user": {
            "displayName": "Peter Shen",
            "photoUrl": "//lh3.googleusercontent.com/-4U4XtPOliU0/AAAAAAAAAAI/AAAAAAAAAYc/8wgnQdDGnvA/s50-c-k-no/photo.jpg",
            "userId": "101608421039751327941"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "esZWF8MOlysl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0add5cf4-9b8e-4a66-da65-ec0c85dc1dcc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525144139538,
          "user_tz": 240,
          "elapsed": 1486,
          "user": {
            "displayName": "Peter Shen",
            "photoUrl": "//lh3.googleusercontent.com/-4U4XtPOliU0/AAAAAAAAAAI/AAAAAAAAAYc/8wgnQdDGnvA/s50-c-k-no/photo.jpg",
            "userId": "101608421039751327941"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 3903660\r\n",
            "drwxr-xr-x 1 root root       4096 Apr 30 16:29 datalab\r\n",
            "-rw-r--r-- 1 root root   23018003 May  1 01:22 data_x_10k.txt?dl=1\r\n",
            "-rw-r--r-- 1 root root      20000 May  1 03:08 data_y_10k_binary.txt?dl=1\r\n",
            "-rw-r--r-- 1 root root      22551 May  1 01:22 data_y_10k.txt?dl=1\r\n",
            "-rw-rw-r-- 1 root root  347116733 Aug  4  2014 glove.6B.100d.txt\r\n",
            "-rw-rw-r-- 1 root root  693432828 Aug  4  2014 glove.6B.200d.txt\r\n",
            "-rw-rw-r-- 1 root root 1037962819 Aug 27  2014 glove.6B.300d.txt\r\n",
            "-rw-rw-r-- 1 root root  171350079 Aug  4  2014 glove.6B.50d.txt\r\n",
            "-rw-r--r-- 1 root root  862182613 Oct 25  2015 glove.6B.zip\r\n",
            "-rw-r--r-- 1 root root  862182613 Oct 25  2015 glove.6B.zip.1\r\n",
            "drwxr-xr-x 3 root root       4096 May  1 01:24 Graph\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LUL_zLQUDjjW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "3993152b-b920-431b-bb54-c21fc80ae19e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525140486150,
          "user_tz": 240,
          "elapsed": 5967,
          "user": {
            "displayName": "Jiaqi Xie",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "117028947960220774647"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/tz0b8pyicdzxq6e/data_x_10k.txt?dl=1\n",
        "!wget https://www.dropbox.com/s/p25b85u7ipoq76q/data_y_10k.txt?dl=1\n",
        "\n",
        "# !wget https://www.dropbox.com/s/rpomqeltu05b4mq/data_y.txt?dl=1\n",
        "# !wget https://www.dropbox.com/s/2kglvav3gf27xf2/data_x.txt?dl=1\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-01 02:08:01--  https://www.dropbox.com/s/tz0b8pyicdzxq6e/data_x_10k.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://dl.dropboxusercontent.com/content_link/0Snzag9JS75z1PVtR8zWeym21gwOImPzNh49sUxTuhKJmqVi6zBM2ZdHpEmnbe53/file?dl=1 [following]\n",
            "--2018-05-01 02:08:02--  https://dl.dropboxusercontent.com/content_link/0Snzag9JS75z1PVtR8zWeym21gwOImPzNh49sUxTuhKJmqVi6zBM2ZdHpEmnbe53/file?dl=1\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23018003 (22M) [application/binary]\n",
            "Saving to: ‘data_x_10k.txt?dl=1’\n",
            "\n",
            "data_x_10k.txt?dl=1 100%[===================>]  21.95M  23.7MB/s    in 0.9s    \n",
            "\n",
            "2018-05-01 02:08:04 (23.7 MB/s) - ‘data_x_10k.txt?dl=1’ saved [23018003/23018003]\n",
            "\n",
            "--2018-05-01 02:08:05--  https://www.dropbox.com/s/p25b85u7ipoq76q/data_y_10k.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://dl.dropboxusercontent.com/content_link/Jkm07XHSgoyx5CfQUFg66Rn2UCgJWZhRdO4WFT1SCgBzv5mTlk2EWWI3Lx6BqU9e/file?dl=1 [following]\n",
            "--2018-05-01 02:08:05--  https://dl.dropboxusercontent.com/content_link/Jkm07XHSgoyx5CfQUFg66Rn2UCgJWZhRdO4WFT1SCgBzv5mTlk2EWWI3Lx6BqU9e/file?dl=1\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22551 (22K) [application/binary]\n",
            "Saving to: ‘data_y_10k.txt?dl=1’\n",
            "\n",
            "data_y_10k.txt?dl=1 100%[===================>]  22.02K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2018-05-01 02:08:06 (1.24 MB/s) - ‘data_y_10k.txt?dl=1’ saved [22551/22551]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SYyjbQC6pSLr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "213bad60-6ace-471b-a7c0-c871b3eae2f5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525144134522,
          "user_tz": 240,
          "elapsed": 2089,
          "user": {
            "displayName": "Peter Shen",
            "photoUrl": "//lh3.googleusercontent.com/-4U4XtPOliU0/AAAAAAAAAAI/AAAAAAAAAYc/8wgnQdDGnvA/s50-c-k-no/photo.jpg",
            "userId": "101608421039751327941"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/q11fuc9qljjrft2/data_y_10k_binary.txt?dl=1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-01 03:08:53--  https://www.dropbox.com/s/q11fuc9qljjrft2/data_y_10k_binary.txt?dl=1\r\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.7.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.7.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://dl.dropboxusercontent.com/content_link/Ob8LwHVOhLqxB455lMnzckLHJxGfpYVu9veG01N86bQQYuMMTb3fnovNIODHaXJO/file?dl=1 [following]\n",
            "--2018-05-01 03:08:53--  https://dl.dropboxusercontent.com/content_link/Ob8LwHVOhLqxB455lMnzckLHJxGfpYVu9veG01N86bQQYuMMTb3fnovNIODHaXJO/file?dl=1\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:601a:6::a27d:706\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20000 (20K) [application/binary]\n",
            "Saving to: ‘data_y_10k_binary.txt?dl=1’\n",
            "\n",
            "data_y_10k_binary.t 100%[===================>]  19.53K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2018-05-01 03:08:54 (3.12 MB/s) - ‘data_y_10k_binary.txt?dl=1’ saved [20000/20000]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LRBk4ou2YhhC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''This script loads pre-trained word embeddings (GloVe embeddings)\n",
        "into a frozen Keras Embedding layer, and uses it to\n",
        "train a text classification model.\n",
        "\n",
        "GloVe embedding data can be found at:\n",
        "http://nlp.stanford.edu/data/glove.6B.zip\n",
        "(source page: http://nlp.stanford.edu/projects/glove/)\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import json\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, GaussianNoise, regularizers\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y_%m_%d')\n",
        "\n",
        "BASE_DIR = './'\n",
        "GLOVE_DIR = BASE_DIR\n",
        "GLOVE_EMBEDDING = 'glove.6B.100d.txt'\n",
        "SAVE_DIR = BASE_DIR + 'models/' + st + '/'\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "data_x_file = 'data_x_10k.txt?dl=1'\n",
        "data_y_file = 'data_y_10k.txt?dl=1'\n",
        "data_y_cat = 'data_y_10k_binary.txt?dl=1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mxrmh6PFYhhH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d84c197-183f-41eb-f92e-2053df652b1b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525144028980,
          "user_tz": 240,
          "elapsed": 12928,
          "user": {
            "displayName": "Peter Shen",
            "photoUrl": "//lh3.googleusercontent.com/-4U4XtPOliU0/AAAAAAAAAAI/AAAAAAAAAYc/8wgnQdDGnvA/s50-c-k-no/photo.jpg",
            "userId": "101608421039751327941"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# first, build index mapping words in the embeddings set\n",
        "# to their embedding vector\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(os.path.join(GLOVE_DIR, GLOVE_EMBEDDING)) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eRmeROrWYhhK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# read in the text files\n",
        "texts_file = open(data_x_file, \"r\")\n",
        "texts = texts_file.readlines()\n",
        "texts_file.close()\n",
        "\n",
        "labels = np.loadtxt(data_y_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sC2MKdskYhhM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a64ab678-9bf1-4fbf-d2e4-0f7124c1c32d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525144156092,
          "user_tz": 240,
          "elapsed": 4576,
          "user": {
            "displayName": "Peter Shen",
            "photoUrl": "//lh3.googleusercontent.com/-4U4XtPOliU0/AAAAAAAAAAI/AAAAAAAAAYc/8wgnQdDGnvA/s50-c-k-no/photo.jpg",
            "userId": "101608421039751327941"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# prepare text samples and their labels\n",
        "print('Processing text dataset')\n",
        "\n",
        "# finally, vectorize the text samples into a 2D integer tensor\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "### TODO: we need to change this to a number not categorical\n",
        "# labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "\n",
        "# split the data into a training set and a validation set\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "# labels = labels[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = data[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]\n",
        "y_train.reshape(len(y_train), 1).shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing text dataset\n",
            "Found 6925 unique tokens.\n",
            "Shape of data tensor: (10000, 1000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "eWQvAqiOYhhP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# prepare embedding matrix\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# load pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='float32')\n",
        "embedded_sequences = embedding_layer(sequence_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OZMayBuWYhhR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "cellView": "code",
        "outputId": "54e255f0-8bb3-4443-bb83-340727225310"
      },
      "cell_type": "code",
      "source": [
        "print('Training model.')\n",
        "tbCallBack = TensorBoard(log_dir='./Graph/{}/'.format(st), histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "# train a 1D convnet with global maxpooling\n",
        "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "# x = GaussianNoise(0.2)(x)\n",
        "x = MaxPooling1D(5)(x)\n",
        "# x = Conv1D(128, 5, activation='relu', kernel_regularizer=regularizers.l1(0.05))(x)\n",
        "x = Conv1D(128, 5, activation='relu')(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "preds = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "opt = Adam(lr=0.0001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['acc'], )\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=50,\n",
        "          validation_split=0.2,\n",
        "#           callbacks=[tbCallBack],\n",
        "          verbose=1)\n",
        "\n",
        "loss, acc = model.evaluate(x_val, y_val,\n",
        "                           batch_size=512)\n",
        "\n",
        "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n",
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/50\n",
            "6400/6400 [==============================] - 66s 10ms/step - loss: 0.7330 - acc: 0.5008 - val_loss: 0.6967 - val_acc: 0.4838\n",
            "Epoch 2/50\n",
            "6400/6400 [==============================] - 65s 10ms/step - loss: 0.6993 - acc: 0.5191 - val_loss: 0.6930 - val_acc: 0.5088\n",
            "Epoch 3/50\n",
            "6400/6400 [==============================] - 66s 10ms/step - loss: 0.6975 - acc: 0.5203 - val_loss: 0.6964 - val_acc: 0.4950\n",
            "Epoch 4/50\n",
            "1216/6400 [====>.........................] - ETA: 49s - loss: 0.6940 - acc: 0.5296"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 65s 10ms/step - loss: 0.6937 - acc: 0.5222 - val_loss: 0.6946 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "6400/6400 [==============================] - 64s 10ms/step - loss: 0.6922 - acc: 0.5306 - val_loss: 0.6997 - val_acc: 0.4919\n",
            "Epoch 6/50\n",
            "6400/6400 [==============================] - 64s 10ms/step - loss: 0.6864 - acc: 0.5416 - val_loss: 0.6997 - val_acc: 0.4838\n",
            "Epoch 7/50\n",
            "4544/6400 [====================>.........] - ETA: 16s - loss: 0.6895 - acc: 0.5359"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 63s 10ms/step - loss: 0.6900 - acc: 0.5336 - val_loss: 0.6936 - val_acc: 0.4981\n",
            "Epoch 8/50\n",
            "6400/6400 [==============================] - 64s 10ms/step - loss: 0.6836 - acc: 0.5522 - val_loss: 0.6945 - val_acc: 0.5088\n",
            "Epoch 9/50\n",
            "6400/6400 [==============================] - 64s 10ms/step - loss: 0.6792 - acc: 0.5678 - val_loss: 0.6936 - val_acc: 0.5094\n",
            "Epoch 10/50\n",
            "5120/6400 [=======================>......] - ETA: 11s - loss: 0.6769 - acc: 0.5750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 65s 10ms/step - loss: 0.6766 - acc: 0.5745 - val_loss: 0.7027 - val_acc: 0.4919\n",
            "Epoch 11/50\n",
            "6400/6400 [==============================] - 66s 10ms/step - loss: 0.6759 - acc: 0.5814 - val_loss: 0.6955 - val_acc: 0.5062\n",
            "Epoch 12/50\n",
            "6400/6400 [==============================] - 65s 10ms/step - loss: 0.6673 - acc: 0.5892 - val_loss: 0.6934 - val_acc: 0.5125\n",
            "Epoch 13/50\n",
            "5120/6400 [=======================>......] - ETA: 12s - loss: 0.6648 - acc: 0.6035"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 65s 10ms/step - loss: 0.6657 - acc: 0.6020 - val_loss: 0.6952 - val_acc: 0.5031\n",
            "Epoch 14/50\n",
            "6400/6400 [==============================] - 68s 11ms/step - loss: 0.6593 - acc: 0.6153 - val_loss: 0.6946 - val_acc: 0.5106\n",
            "Epoch 15/50\n",
            "6400/6400 [==============================] - 68s 11ms/step - loss: 0.6556 - acc: 0.6188 - val_loss: 0.6986 - val_acc: 0.5038\n",
            "Epoch 16/50\n",
            "5120/6400 [=======================>......] - ETA: 12s - loss: 0.6459 - acc: 0.6357"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6400/6400 [==============================] - 68s 11ms/step - loss: 0.6447 - acc: 0.6375 - val_loss: 0.6950 - val_acc: 0.5288\n",
            "Epoch 17/50\n",
            "6272/6400 [============================>.] - ETA: 1s - loss: 0.6363 - acc: 0.6405"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xuH7VykGS56S",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1425
        },
        "outputId": "d6f4ecc9-02bd-45f3-da3e-16d7d9a7a45f",
        "executionInfo": {
          "status": "error",
          "timestamp": 1525144645930,
          "user_tz": 240,
          "elapsed": 98375,
          "user": {
            "displayName": "Peter Shen",
            "photoUrl": "//lh3.googleusercontent.com/-4U4XtPOliU0/AAAAAAAAAAI/AAAAAAAAAYc/8wgnQdDGnvA/s50-c-k-no/photo.jpg",
            "userId": "101608421039751327941"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Activation, Dropout, Embedding, Input, Dropout, TimeDistributed, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.recurrent import GRU\n",
        "\n",
        "hidden_size = 128\n",
        "# input = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "x = Embedding(input_dim = MAX_NUM_WORDS, output_dim = 120)(sequence_input)\n",
        "# x = GaussianNoise(0.2)(x)\n",
        "# x = LSTM(units = 128, dropout=0.25)(x)\n",
        "x = LSTM(hidden_size, return_sequences=True)(x)\n",
        "# x = LSTM(hidden_size, return_sequences=True)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "# x = TimeDistributed(Dense(MAX_NUM_WORDS))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(1, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=sequence_input,outputs=x)\n",
        "\n",
        "opt = Adam(lr=0.0005)\n",
        "\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train[0:1000],y_train[0:1000],epochs=5, validation_split=0.2, batch_size = 128)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 32s 40ms/step - loss: 8.2103 - acc: 0.4850 - val_loss: 8.7683 - val_acc: 0.4500\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 30s 38ms/step - loss: 8.2103 - acc: 0.4850 - val_loss: 8.7683 - val_acc: 0.4500\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 30s 38ms/step - loss: 8.2103 - acc: 0.4850 - val_loss: 8.7683 - val_acc: 0.4500\n",
            "Epoch 4/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-841b1bb0b0c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qbdnZoUzcnfw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ddce3da9-f919-4567-ec86-b9cc8e07ca1e"
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Activation, Dropout, Embedding, Input, Flatten, TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.recurrent import GRU\n",
        "\n",
        "hidden_size = 128\n",
        "model = Sequential()\n",
        "x = Embedding(input_dim = MAX_NUM_WORDS, output_dim = 128, input_length = 1000)\n",
        "model.add(x)\n",
        "model.add(LSTM(hidden_size, return_sequences=True))\n",
        "model.add(LSTM(hidden_size, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(TimeDistributed(Dense(MAX_NUM_WORDS)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "opt = Adam(lr=0.0001)\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,epochs=10, validation_split=0.2, batch_size = 512)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qq7QLTA6eNvp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "72e26575-1aef-40a6-db11-c40903c277f2",
        "executionInfo": {
          "status": "error",
          "timestamp": 1525141645869,
          "user_tz": 240,
          "elapsed": 392,
          "user": {
            "displayName": "Jiaqi Xie",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "117028947960220774647"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_NUM_WORDS"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ab870b3405e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMAX_NUM_WORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'MAX_NUM_WORDS' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_t3b-_u_YhhU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "e224c3e6-3599-476c-dd21-e33c0f29f835",
        "executionInfo": {
          "status": "error",
          "timestamp": 1525140511743,
          "user_tz": 240,
          "elapsed": 521,
          "user": {
            "displayName": "Jiaqi Xie",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "117028947960220774647"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# save the model output\n",
        "\n",
        "import pickle\n",
        "\n",
        "os.makedirs(SAVE_DIR)\n",
        "\n",
        "model.save(SAVE_DIR + \"model.h5\")\n",
        "\n",
        "# saving tokenizer\n",
        "with open(SAVE_DIR + 'tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-14844ad18f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# saving tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-NFA1lPjTXXO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
=======
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/notes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rm = data[data.category != \"Discharge summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id                                                31038\n",
       "hadm_id                                                  174978\n",
       "category                                                   Echo\n",
       "text          PATIENT/TEST INFORMATION:\\nIndication: Endocar...\n",
       "duration                                        2 days 10:48:49\n",
       "Name: 55876, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rm.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2294687, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2358870, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rm.to_csv(\"../data/notes_no_discharge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> origin/master
